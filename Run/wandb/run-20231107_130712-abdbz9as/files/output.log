UNet(
  (e1): encoder_block(
    (conv): conv_block(
      (conv1): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU()
    )
    (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  )
  (e2): encoder_block(
    (conv): conv_block(
      (conv1): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU()
    )
    (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  )
  (e3): encoder_block(
    (conv): conv_block(
      (conv1): Conv2d(24, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU()
    )
    (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  )
  (e4): encoder_block(
    (conv): conv_block(
      (conv1): Conv2d(48, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU()
    )
    (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)
  )
  (b): conv_block(
    (conv1): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu): ReLU()
  )
  (d1): decoder_block(
    (up): ConvTranspose2d(192, 96, kernel_size=(2, 2), stride=(2, 2))
    (conv): conv_block(
      (conv1): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU()
    )
  )
  (d2): decoder_block(
    (up): ConvTranspose2d(96, 48, kernel_size=(2, 2), stride=(2, 2))
    (conv): conv_block(
      (conv1): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU()
    )
  )
  (d3): decoder_block(
    (up): ConvTranspose2d(48, 24, kernel_size=(2, 2), stride=(2, 2))
    (conv): conv_block(
      (conv1): Conv2d(48, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU()
    )
  )
  (d4): decoder_block(
    (up): ConvTranspose2d(24, 12, kernel_size=(2, 2), stride=(2, 2))
    (conv): conv_block(
      (conv1): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (conv2): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (relu): ReLU()
    )
  )
  (outputs): Conv2d(12, 3, kernel_size=(1, 1), stride=(1, 1))
)
Traceback (most recent call last):
  File "/home/kebl6872/REFUGE_4YP/Run/wandb_train.py", line 160, in model_pipeline
    train(model,train_loader,test_loader,criterion,eval_criterion,optimizer,config)
  File "/home/kebl6872/REFUGE_4YP/Run/wandb_train.py", line 106, in train
    loss = train_batch(images,labels,model,optimizer,criterion)
  File "/home/kebl6872/REFUGE_4YP/Run/wandb_train.py", line 38, in train_batch
    outputs = model(images)
  File "/home/kebl6872/miniconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1128, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/kebl6872/REFUGE_4YP/Run/UNET/UNet_model.py", line 82, in forward
    s1, p1 = self.e1(inputs)
  File "/home/kebl6872/miniconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/kebl6872/REFUGE_4YP/Run/UNET/UNet_model.py", line 40, in forward
    x = self.conv(inputs)
  File "/home/kebl6872/miniconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/kebl6872/REFUGE_4YP/Run/UNET/UNet_model.py", line 20, in forward
    x = self.conv1(inputs)
  File "/home/kebl6872/miniconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/kebl6872/miniconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/kebl6872/miniconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same