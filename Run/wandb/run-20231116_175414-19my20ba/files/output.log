Training dataset size: 400
Validation dataset size: 400
  0%|                                                    | 0/50 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/kebl6872/REFUGE_4YP/Run/wandb_train.py", line 232, in model_pipeline
    train(model,train_loader,test_loader,criterion,eval_criterion,config)
  File "/home/kebl6872/REFUGE_4YP/Run/wandb_train.py", line 140, in train
    loss = train_batch(images,labels,model,optimizer,criterion)
  File "/home/kebl6872/REFUGE_4YP/Run/wandb_train.py", line 40, in train_batch
    outputs = model(images)
  File "/home/kebl6872/miniconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1128, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/kebl6872/REFUGE_4YP/Run/UNET/UNet_model.py", line 92, in forward
    d2 = self.d2(d1, s3)
  File "/home/kebl6872/miniconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/kebl6872/REFUGE_4YP/Run/UNET/UNet_model.py", line 55, in forward
    x = self.conv(x)
  File "/home/kebl6872/miniconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/kebl6872/REFUGE_4YP/Run/UNET/UNet_model.py", line 28, in forward
    x = self.relu(x)
  File "/home/kebl6872/miniconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/kebl6872/miniconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/kebl6872/miniconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/functional.py", line 1442, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 288.00 MiB (GPU 0; 10.90 GiB total capacity; 9.43 GiB already allocated; 179.38 MiB free; 9.51 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF