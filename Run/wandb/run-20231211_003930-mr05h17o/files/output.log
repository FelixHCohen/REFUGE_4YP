Training dataset size: 400
Training dataset size: 400
  0%|                                                  | 0/1000 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/home/kebl6872/REFUGE_4YP/Run/PromptUNetTrain.py", line 146, in prompt_model_pipeline
    prompt_train(model,train_loader,test_loader,criterion,eval_criterion,config)
  File "/home/kebl6872/REFUGE_4YP/Run/PromptUNetTrain.py", line 98, in prompt_train
    loss = prompt_train_batch(images,labels,points,point_labels,model,optimizer,criterion)
  File "/home/kebl6872/REFUGE_4YP/Run/PromptUNetTrain.py", line 12, in prompt_train_batch
    loss.backward()
  File "/home/kebl6872/miniconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/kebl6872/miniconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [16, 384, 32, 32]], which is output 0 of ReluBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).