Training dataset size: 400
Training dataset size: 400
  0%|                                                  | 0/1000 [00:00<?, ?it/s]/home/kebl6872/miniconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/autograd/__init__.py:173: UserWarning: Error detected in ConvolutionBackward0. Traceback of forward call that caused the error:
  File "/home/kebl6872/REFUGE_4YP/Run/PromptUNetTrain.py", line 174, in <module>
    model = prompt_model_pipeline(config)
  File "/home/kebl6872/REFUGE_4YP/Run/PromptUNetTrain.py", line 146, in prompt_model_pipeline
    prompt_train(model,train_loader,test_loader,criterion,eval_criterion,config)
  File "/home/kebl6872/REFUGE_4YP/Run/PromptUNetTrain.py", line 98, in prompt_train
    loss = prompt_train_batch(images,labels,points,point_labels,model,optimizer,criterion)
  File "/home/kebl6872/REFUGE_4YP/Run/PromptUNetTrain.py", line 9, in prompt_train_batch
    outputs = model(images,point_input,point_label_input)
  File "/home/kebl6872/miniconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1128, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/kebl6872/REFUGE_4YP/Run/PromptUNet/PromptUNet.py", line 124, in forward
    outputs = self.outputs(d4)
  File "/home/kebl6872/miniconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/kebl6872/miniconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 447, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/kebl6872/miniconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/nn/modules/conv.py", line 443, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
 (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755897462/work/torch/csrc/autograd/python_anomaly_mode.cpp:104.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  0%|                                                  | 0/1000 [00:02<?, ?it/s]
Traceback (most recent call last):
  File "/home/kebl6872/REFUGE_4YP/Run/PromptUNetTrain.py", line 146, in prompt_model_pipeline
    prompt_train(model,train_loader,test_loader,criterion,eval_criterion,config)
  File "/home/kebl6872/REFUGE_4YP/Run/PromptUNetTrain.py", line 98, in prompt_train
    loss = prompt_train_batch(images,labels,points,point_labels,model,optimizer,criterion)
  File "/home/kebl6872/REFUGE_4YP/Run/PromptUNetTrain.py", line 12, in prompt_train_batch
    loss.backward()
  File "/home/kebl6872/miniconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/_tensor.py", line 363, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/kebl6872/miniconda3/envs/pytorch_env/lib/python3.10/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA out of memory. Tried to allocate 180.00 MiB (GPU 0; 10.90 GiB total capacity; 8.84 GiB already allocated; 131.06 MiB free; 9.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF